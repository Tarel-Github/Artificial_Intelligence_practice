{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPNfXvL16s/Oe580Mp1dHZ/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 2개의 층"],"metadata":{"id":"HCfNFIlxr3Ll"}},{"cell_type":"code","execution_count":18,"metadata":{"id":"y8nobnovrXM0","executionInfo":{"status":"ok","timestamp":1681476980208,"user_tz":-540,"elapsed":1283,"user":{"displayName":"손민성","userId":"15408184320550549324"}}},"outputs":[],"source":["# 케라스 API 를 사용해서 패션 MNIST 데이터셋을 로드\n","from tensorflow import keras\n","(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data() # 책과는 연산식 부분이 약간 다름"]},{"cell_type":"markdown","source":["이미지를 로드한 다음  \n","픽셀값을 0 ~ 255 범위에서 0 ~ 1 사이로 변환하고, 28 * 28 크기의  \n","2차원 배열을 784 크기의 1차원 배열로 펼친다.  \n","마지막으로 사이킷런의 train_test_split()함수로 훈련세트와 검증세트를 분할  \n"],"metadata":{"id":"xUvhOHd2sOo8"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","train_scaled = train_input / 255.0\n","train_scaled = train_scaled.reshape(-1, 28 * 28)\n","train_scaled, val_scaled, train_target, val_target = train_test_split(\n","    train_scaled, train_target, test_size = 0.2, random_state = 42\n",")"],"metadata":{"id":"L40XZi5YsOQ3","executionInfo":{"status":"ok","timestamp":1681476982344,"user_tz":-540,"elapsed":1068,"user":{"displayName":"손민성","userId":"15408184320550549324"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["이제 인공신경망 모델에 층을 2개 추가한다.  \n","전에 만든 것과 차이점은 입력층과 출력층 사이에 밀집층이 추가되는 것이다.  \n","이러한 입력층 ~ 출력층 사이의 모든 층을 <b>은닉층</b>이라고 한다.  \n","은닉층에는 활성화 함수가 있다.  \n","  \n","\n","출력층에 적용하는 함수는 다음으로 제한된다.  \n","이진분류일 경우 시그모이드 함수를 사용하고  \n","다중분류일 경우 소프트맥스 함수를 사용한다.  \n","  \n","하지만 은닉층의 활성화 함수는 비교적 자유롭다.  \n","주로 시그모이드 함수와 볼 렐루 함수 등을 사용한다.  \n","  \n","시그모이드 함수는 뉴런의 출력 z값을 0과 1사이로 압축한다.  \n","  \n","  \n","\n","---\n","시그모이드 함수를 사용한 은닉층과  \n","소프트맥스 함수를 사용한 출력층을  \n","각각의 Dense 클래스로 만들어보자  "],"metadata":{"id":"o0o7A7FSt2XL"}},{"cell_type":"code","source":["dense1 = keras.layers.Dense(100, activation = 'sigmoid', input_shape=(784,))  # 은닉층의 뉴런의 수를 정하는 것에는 특별한 기준이 없다. 즉 경험에 의존해야 한다.\n","dense2 = keras.layers.Dense(10, activation = 'softmax')"],"metadata":{"id":"skXYD75Lwova","executionInfo":{"status":"ok","timestamp":1681476982344,"user_tz":-540,"elapsed":36,"user":{"displayName":"손민성","userId":"15408184320550549324"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["dense1은 은닉층이고 100개의 뉴런을 가진 밀집층이다. 활성화 함수로 시그모이드를 사용하고 입력의 크기를 784로 지정했다.  \n","dense2는 출력층이고  10개의 뉴런을 가졌고 소프트맥스 함수를 활성함수로 지정했다.  \n"],"metadata":{"id":"X-hwcp0HyBpi"}},{"cell_type":"markdown","source":["# 심층 신경망 만들기\n","이제 dense1과 dense2를 Sequential 클래스에 추가해서 심층 신경망을 만들어보자\n"],"metadata":{"id":"vq0xvotXymtl"}},{"cell_type":"code","source":["model = keras.Sequential([dense1, dense2])"],"metadata":{"id":"T6hXaLxcUigc","executionInfo":{"status":"ok","timestamp":1681476982344,"user_tz":-540,"elapsed":35,"user":{"displayName":"손민성","userId":"15408184320550549324"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["dense1과 dense2를 리스트로 만들어 전달한다.  \n","출력층은 가장 마지막에 두어야 한다.  \n","\n","---\n","인공신경망의 강력한 성능은 이렇게 층을 추가하여 입력 데이터에 대해 연속적인 학습을 진행하는 능력에서 나온다.  \n","케라스는 모델의 summary() 메서드를 호출하면 층에 대한 유용한 정보를 얻을 수 있다.\n"],"metadata":{"id":"UbmdGV7TUoT_"}},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BBtkUs43r7Ge","executionInfo":{"status":"ok","timestamp":1681476982345,"user_tz":-540,"elapsed":36,"user":{"displayName":"손민성","userId":"15408184320550549324"}},"outputId":"26ae8672-fc71-481e-d915-c77a54709e47"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_6 (Dense)             (None, 100)               78500     \n","                                                                 \n"," dense_7 (Dense)             (None, 10)                1010      \n","                                                                 \n","=================================================================\n","Total params: 79,510\n","Trainable params: 79,510\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["모델이름 sequential  \n","층의 이름을 지정하지 않으면 dense로 초기화  \n","출력크기는 (None, 100)  \n","여기서 None은 샘플 개수가 정의되어 있지 않기 때문에 None이며  \n","은닉층의 뉴런개수가 100개이므로 100개의 출력이 나온다.  \n","즉, 샘플마다 784개의 픽셀값이 은닉층을 통과하면서 100개의 특성으로 압축되었다.  \n","파라미터는 78500개다.  \n","이는 784개의 픽셀 * 100개의 뉴런 + 100개의 절편(뉴런마다 1개)으로 이루어진다.  \n","이는 784개의 픽셀과 100개의 모든 조합에 대한 가중치다.  \n","\n","---\n","\n","두 번째 층의 출력 크기는(None, 10)  \n","즉, 뉴런 개수가 10개다.  \n","파라미터는 100개의 은닉뉴런층 * 10개의 출력층 뉴런 + 출력층의 뉴런마다 하나의 절편(10) 이므로  \n","100 * 10 + 10 이므로 1010개이다.\n","\n","---\n","\n","summary() 메서드의 마지막에는  \n","총 모델 파라미터 개수(78500 + 1010)와  \n","훈련되는 파라미터 수가 나온다.  \n","그 아래 Non-trainable params는 훈련되지 않은 파라미터의 수다.  \n"],"metadata":{"id":"3TPpf6x4s_QK"}},{"cell_type":"markdown","source":["# 층을 추가하는 다른 방법\n","앞에서는 Dense 클래스의 객체 dense1, dense2를 만들어 sequential 클래스에 전달했다.  \n","두 객체를 따로 저장해서 쓸 일이 없기에 Sequential 클래스 생성자 안에 Dense 클래스 객체를 만드는 경우가 많았다."],"metadata":{"id":"cLQwJxYtvQ21"}},{"cell_type":"markdown","source":["## 방법 1"],"metadata":{"id":"LyAJJgUIzUff"}},{"cell_type":"code","source":["model = keras.Sequential([keras.layers.Dense(100, activation='sigmoid', input_shape=(784,), name='hidden'), keras.layers.Dense(10, activation = 'softmax', name='output')], name='패션 MNIST 모델')"],"metadata":{"id":"xOA4h5-JvlG5","executionInfo":{"status":"ok","timestamp":1681476982345,"user_tz":-540,"elapsed":28,"user":{"displayName":"손민성","userId":"15408184320550549324"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XF6VA4lYwVq5","executionInfo":{"status":"ok","timestamp":1681476982346,"user_tz":-540,"elapsed":28,"user":{"displayName":"손민성","userId":"15408184320550549324"}},"outputId":"095bbbbb-365a-40df-d106-2021f9414a55"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"패션 MNIST 모델\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," hidden (Dense)              (None, 100)               78500     \n","                                                                 \n"," output (Dense)              (None, 10)                1010      \n","                                                                 \n","=================================================================\n","Total params: 79,510\n","Trainable params: 79,510\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["위 방법은 추가되는 층을 한 눈에 쉽게 볼 수 있다는 장점이 있다."],"metadata":{"id":"1kmXPCOEzFOi"}},{"cell_type":"markdown","source":["# 방법 2"],"metadata":{"id":"P-NFbQEXzXIJ"}},{"cell_type":"code","source":["model = keras.Sequential()\n","model.add(keras.layers.Dense(100, activation = 'sigmoid', input_shape=(784,)))\n","model.add(keras.layers.Dense(10, activation = 'softmax'))"],"metadata":{"id":"mDyFiXCAwck5","executionInfo":{"status":"ok","timestamp":1681476982346,"user_tz":-540,"elapsed":19,"user":{"displayName":"손민성","userId":"15408184320550549324"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H2M7vXQ9zZCG","executionInfo":{"status":"ok","timestamp":1681476982347,"user_tz":-540,"elapsed":20,"user":{"displayName":"손민성","userId":"15408184320550549324"}},"outputId":"3ae5a621-9738-4285-cc9c-439ce3ecb63f"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_8 (Dense)             (None, 100)               78500     \n","                                                                 \n"," dense_9 (Dense)             (None, 10)                1010      \n","                                                                 \n","=================================================================\n","Total params: 79,510\n","Trainable params: 79,510\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["Sequential 클래스의 객체를 만들고 이 객체의 add() 메서드를 호출하여 층을 추가하는 방식이다.  \n"],"metadata":{"id":"bSuV0yIDykUH"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"Qvqy6pjKzisu"}},{"cell_type":"code","source":["# 모델 훈련, 에포크는 5번\n","model.compile(loss='sparse_categorical_crossentropy', metrics = 'accuracy')\n","model.fit(train_scaled, train_target, epochs = 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VSi2Gnygzjvn","executionInfo":{"status":"ok","timestamp":1681477023787,"user_tz":-540,"elapsed":41451,"user":{"displayName":"손민성","userId":"15408184320550549324"}},"outputId":"3a3e39ae-a04f-40ff-925f-fad9a78d5dee"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1500/1500 [==============================] - 5s 3ms/step - loss: 0.5661 - accuracy: 0.8056\n","Epoch 2/5\n","1500/1500 [==============================] - 9s 6ms/step - loss: 0.4118 - accuracy: 0.8505\n","Epoch 3/5\n","1500/1500 [==============================] - 8s 5ms/step - loss: 0.3772 - accuracy: 0.8646\n","Epoch 4/5\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.3532 - accuracy: 0.8730\n","Epoch 5/5\n","1500/1500 [==============================] - 5s 4ms/step - loss: 0.3359 - accuracy: 0.8767\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7eff54891e20>"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","source":["추가된 층이 성능을 향상시켰다."],"metadata":{"id":"jXxTtSXE9rxu"}},{"cell_type":"markdown","source":["# 렐루 함수\n","시그모이드 함수는 그래프를 보면 왼쪽과 오른쪽 끝으로 갈 수록 그래프가 누워버리기 때문에  \n","올바른 출력을 만드는데 신속하게 대응하지 못한다.  \n","특히 층이 많을 수록 그 효과가 누적되에 학습을 어렵게 한다.  \n","그래서 만들어진 것이 바로 렐루 함수다.  \n","렐루 함수는 입력이 양수면 그냥 입력을 통과시키고 음수일 경우에는 0으로 만든다.  \n"],"metadata":{"id":"QsO0QtQB9w6E"}},{"cell_type":"code","source":["model = keras.Sequential()\n","model.add(keras.layers.Flatten(input_shape=(28, 28)))\n","model.add(keras.layers.Dense(100, activation = 'relu'))\n","model.add(keras.layers.Dense(10, activation = 'softmax'))"],"metadata":{"id":"7i5OFdtGkKWK","executionInfo":{"status":"ok","timestamp":1681477023787,"user_tz":-540,"elapsed":32,"user":{"displayName":"손민성","userId":"15408184320550549324"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["첫 번째 Dense 층에 있던 input_shape 매개변수를 Flatten층으로 옮긴다.  \n","첫 번째 Dense 층의 활성화 함수를 relu로 바꿨다.  "],"metadata":{"id":"xdKeRhwikJsl"}},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mbWQZq0Wl6sn","executionInfo":{"status":"ok","timestamp":1681477023788,"user_tz":-540,"elapsed":31,"user":{"displayName":"손민성","userId":"15408184320550549324"}},"outputId":"ba283460-3157-459e-8e22-e2bc6c446206"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_1 (Flatten)         (None, 784)               0         \n","                                                                 \n"," dense_10 (Dense)            (None, 100)               78500     \n","                                                                 \n"," dense_11 (Dense)            (None, 10)                1010      \n","                                                                 \n","=================================================================\n","Total params: 79,510\n","Trainable params: 79,510\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["flatten의 파라미터는 0개인데 이는 학습하는 층이 아니라서 그렇다.  \n","---\n","훈련데이터를 다시 준비해서 모델을 훈련해보자  \n","reshape() 메서드를 적용하지 않았다.  "],"metadata":{"id":"U5leL5VGmBIC"}},{"cell_type":"code","source":["(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n","train_scaled = train_input / 255.0\n","train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state = 42)"],"metadata":{"id":"SPvv2CO4l_ID","executionInfo":{"status":"ok","timestamp":1681477025210,"user_tz":-540,"elapsed":1445,"user":{"displayName":"손민성","userId":"15408184320550549324"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["model.compile(loss='sparse_categorical_crossentropy', metrics = 'accuracy')\n","model.fit(train_scaled, train_target, epochs = 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-0AP3q6smtYA","executionInfo":{"status":"ok","timestamp":1681477047521,"user_tz":-540,"elapsed":22321,"user":{"displayName":"손민성","userId":"15408184320550549324"}},"outputId":"c28258cd-41ab-421f-bd5d-3dcbb8459181"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.5279 - accuracy: 0.8131\n","Epoch 2/5\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.3917 - accuracy: 0.8590\n","Epoch 3/5\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.3543 - accuracy: 0.8725\n","Epoch 4/5\n","1500/1500 [==============================] - 5s 3ms/step - loss: 0.3315 - accuracy: 0.8806\n","Epoch 5/5\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.3138 - accuracy: 0.8870\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7eff547c3fa0>"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["시그모이드 함수를 사용했을 때와 비교하면 성능이 조금 향상되었다."],"metadata":{"id":"YuYrtAwKnZ3O"}},{"cell_type":"code","source":["model.evaluate(val_scaled, val_target)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y3M-RJbBnLW8","executionInfo":{"status":"ok","timestamp":1681477049400,"user_tz":-540,"elapsed":1909,"user":{"displayName":"손민성","userId":"15408184320550549324"}},"outputId":"98db23c2-c462-4b89-ac21-7c6ffc870c62"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["375/375 [==============================] - 1s 2ms/step - loss: 0.3736 - accuracy: 0.8746\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.37357133626937866, 0.8745833039283752]"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","source":["# 옵티마이저\n","하이퍼파라미터는 모델이 학습하지 않아 사람이 지정해주어야 하는 파라미터를 말한다.  \n","신경망에는 특히 하이퍼파라미터가 많다.  \n","여러개의 은닉층을 추가할 수도 있지만 추가할 은닉층의 개수는 하이퍼파라미터다.  \n","은닉층의 뉴런 개수도 하이퍼파라미터다.  \n","활성화 함수도 우리가 선택할 하이퍼파라미터중 하나다.  \n","심지어 층의 종류도 하이퍼파라미터다.  \n","epochs의 매개변수 하이퍼파라미터다.  \n","  \n","---  \n","케라스가 제공하는 다양한 종류의 경사하강법 알고리즘을 옵티마이저라고 부른다.  \n","아래와 같이 사용한다.  \n","model.compile(optimizer='sgd', loss = 'sparse_categorical_crossentropy', metrics ='accuracy')  \n","\n","---\n","기본 경사 하강법 옵티마이저는 모두 SHD 클래스에서 제공한다.  \n","SGD 클래스의 nesterov 매개변수를 True로 바꾸면 네스테로프 모멘텀 최적화를 사용한다.  \n","대부분의 경우, 네스테로프 모멘텀이 기본 확률적 경사 하강법보다 성능이 좋다.  \n","\n","---\n","모델이 최적점에 가까이 가면 학습률을 낮춘다.  \n","이렇게 하면 안정적으로 최적점에 수렴하는데 적응적 학습률이라고 한다.  \n","적응적 학습률을 사용하는 대표적인 옵티마이저는 Adagrad와 RMSprop이다.  "],"metadata":{"id":"bCp340-qnjyh"}},{"cell_type":"code","source":["# Adam 클래스의 매개변수 기본값으로 패션MNIST를 훈련해보자\n","model = keras.Sequential()\n","model.add(keras.layers.Flatten(input_shape=(28, 28)))\n","model.add(keras.layers.Dense(100, activation='relu'))\n","model.add(keras.layers.Dense(10, activation ='softmax'))"],"metadata":{"id":"ErUMUR7p3JwY","executionInfo":{"status":"ok","timestamp":1681480241186,"user_tz":-540,"elapsed":319,"user":{"displayName":"손민성","userId":"15408184320550549324"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["# 컴파일 메서드의 옵티마이저를 아담으로 설정하고 5번의 에포크 동안 훈련\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = 'accuracy')\n","model.fit(train_scaled, train_target, epochs = 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Z8FLeyRCE-I","executionInfo":{"status":"ok","timestamp":1681480426556,"user_tz":-540,"elapsed":42358,"user":{"displayName":"손민성","userId":"15408184320550549324"}},"outputId":"897603ec-6586-458a-80a5-6bf50059b38f"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1500/1500 [==============================] - 6s 3ms/step - loss: 0.5274 - accuracy: 0.8156\n","Epoch 2/5\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.3916 - accuracy: 0.8605\n","Epoch 3/5\n","1500/1500 [==============================] - 7s 5ms/step - loss: 0.3536 - accuracy: 0.8718\n","Epoch 4/5\n","1500/1500 [==============================] - 7s 5ms/step - loss: 0.3276 - accuracy: 0.8807\n","Epoch 5/5\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.3096 - accuracy: 0.8868\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7eff4c18d220>"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","source":["RMSprop를 사용했을 때와 거의 같은 성능을 보여준다."],"metadata":{"id":"uhLvMWLcCqAC"}},{"cell_type":"code","source":["# 성능 확인\n","model.evaluate(val_scaled, val_target)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P0YU89aICcw-","executionInfo":{"status":"ok","timestamp":1681480432710,"user_tz":-540,"elapsed":1577,"user":{"displayName":"손민성","userId":"15408184320550549324"}},"outputId":"2acedf7c-307a-4e63-b95f-7cb99d3eee47"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["375/375 [==============================] - 1s 2ms/step - loss: 0.3246 - accuracy: 0.8814\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.32462435960769653, 0.8814166784286499]"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","source":["기본 RMSprop보다 조금 더 나은 성능이 나왔다."],"metadata":{"id":"LRL3T6wMC0_R"}},{"cell_type":"markdown","source":["# 케라스 API를 활용한 심층 신경망\n","여러 개의 층을 추가해 다층 인공 신경망을 만들어 보았다.  \n","이런 인공 신경망을 심층 신경망이라고 부른다.  \n","또 케라스 API를 통해 층을 추가하는 여러가지 방법을 알아보았다.  \n","\n","# 정리\n","### 심층신경망\n","2개 이상의 층을 포함한 신경망, 다층 인공신경망, 딥러닝 이라고도 한다.  \n","### 렐루 함수\n","이미지 분류 모델의 은닉층에서 많이 사용하는 활성화 함수.  \n","시그모이드 함수와 달리 층이 많아져도 학습곤란 문제가 발생하지 않는다.\n","### 옵티마이저\n","신경망의 가중치와 절편을 학습하기 위한 알고리즘 또는 방법  \n","케라스에는 다양한 경사하강법 알고리즘이 있는데  \n","대표적으로 SGD, 네스테로프모멘텀, RMSprop, Adam 등이다."],"metadata":{"id":"I9A_TjVRC6Wr"}}]}